{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Install necessary libraries (from first code, Cell 1)\n",
        "try:\n",
        "    import torch, torchvision, transformers, torchmetrics, PIL, exifread, requests, google\n",
        "except ImportError:\n",
        "    !pip install torch torchvision transformers torchmetrics pillow exifread requests\n",
        "\n",
        "# Imports and custom dataset (from first code, Cell 2)\n",
        "import os\n",
        "os.environ['TK_SILENCE_DEPRECATION'] = '1'  # Suppress Tkinter warnings\n",
        "from PIL import Image\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import transforms\n",
        "from transformers import ViTModel\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import exifread\n",
        "import requests\n",
        "from google.colab import files\n",
        "\n",
        "class SatelliteWildfireDataset(Dataset):\n",
        "    def __init__(self, image_dir):\n",
        "        self.image_dir = image_dir\n",
        "        self.images = []\n",
        "        self.labels = []\n",
        "        categories = ['Smoke', 'Seaside', 'Land', 'Haze', 'Dust', 'Cloud']\n",
        "        for i in range(len(categories)):\n",
        "            category_name = categories[i]\n",
        "            folder = os.path.join(image_dir, category_name)\n",
        "            if not os.path.exists(folder):\n",
        "                continue\n",
        "            files = os.listdir(folder)\n",
        "            for file in files:\n",
        "                if file.endswith('.tif'):\n",
        "                    self.images.append(os.path.join(folder, file))\n",
        "                    self.labels.append(i)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        image_path = self.images[index]\n",
        "        image = Image.open(image_path).convert('RGB')\n",
        "        label = self.labels[index]\n",
        "        transform = transforms.Compose([\n",
        "            transforms.Resize((224, 224)),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "        ])\n",
        "        image = transform(image)\n",
        "        return image, label\n",
        "\n",
        "# Custom ViT model (from first code, Cell 3)\n",
        "class WildfireViTModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(WildfireViTModel, self).__init__()\n",
        "        self.vit = ViTModel.from_pretrained('google/vit-base-patch16-224')\n",
        "        for parameters in self.vit.parameters():\n",
        "            parameters.requires_grad = False\n",
        "        self.extra_layer = nn.Linear(768, 256)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.final_layer = nn.Linear(256, 6)\n",
        "\n",
        "    def forward(self, input_images):\n",
        "        outputs = self.vit(pixel_values=input_images)\n",
        "        cls_output = outputs.last_hidden_state[:, 0, :]\n",
        "        hidden = self.extra_layer(cls_output)\n",
        "        activated = self.relu(hidden)\n",
        "        logits = self.final_layer(activated)\n",
        "        return logits\n",
        "\n",
        "# Utility functions: classification (first code, Cell 6), GPS, and fire station (second code)\n",
        "def classify_image(image_path, model):\n",
        "    try:\n",
        "        image = Image.open(image_path).convert(\"RGB\")\n",
        "        transform = transforms.Compose([\n",
        "            transforms.Resize((224, 224)),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "        ])\n",
        "        input_tensor = transform(image)\n",
        "        input_batch = input_tensor.unsqueeze(0)\n",
        "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "        input_batch = input_batch.to(device)\n",
        "        model = model.to(device)\n",
        "        with torch.no_grad():\n",
        "            output = model(input_batch)\n",
        "        _, predicted_class = torch.max(output, 1)\n",
        "        class_labels = ['Smoke', 'Seaside', 'Land', 'Haze', 'Dust', 'Cloud']\n",
        "        predicted_label = class_labels[predicted_class.item()]\n",
        "        if predicted_label == 'Smoke':\n",
        "            return f\"Predicted class: {predicted_label}\"\n",
        "        return \"No smoke detected\"\n",
        "    except Exception as e:\n",
        "        return f\"Error classifying image: {e}\"\n",
        "\n",
        "def get_gps_coordinates(image_path):\n",
        "    try:\n",
        "        with open(image_path, 'rb') as f:\n",
        "            tags = exifread.process_file(f)\n",
        "            if all(k in tags for k in ['GPS GPSLatitude', 'GPS GPSLatitudeRef', 'GPS GPSLongitude', 'GPS GPSLongitudeRef']):\n",
        "                lat, lat_ref = tags['GPS GPSLatitude'].values, tags['GPS GPSLatitudeRef'].values\n",
        "                lon, lon_ref = tags['GPS GPSLongitude'].values, tags['GPS GPSLongitudeRef'].values\n",
        "                lat_deg = float(lat[0].num)/float(lat[0].den) + float(lat[1].num)/(float(lat[1].den)*60) + float(lat[2].num)/(float(lat[2].den)*3600)\n",
        "                if lat_ref == 'S':\n",
        "                    lat_deg *= -1\n",
        "                lon_deg = float(lon[0].num)/float(lon[0].den) + float(lon[1].num)/(float(lon[1].den)*60) + float(lon[2].num)/(float(lon[2].den)*3600)\n",
        "                if lon_ref == 'W':\n",
        "                    lon_deg *= -1\n",
        "                return lat_deg, lon_deg\n",
        "    except Exception as e:\n",
        "        print(f\"Error reading EXIF data: {e}\")\n",
        "    return None\n",
        "\n",
        "def get_fire_station_phone_number(lat, lon, api_key):\n",
        "    try:\n",
        "        url = f\"https://places.googleapis.com/v1/places:searchNearby\"\n",
        "        payload = {\n",
        "            \"locationRestriction\": {\n",
        "                \"circle\": {\n",
        "                    \"center\": {\n",
        "                        \"latitude\": lat,\n",
        "                        \"longitude\": lon\n",
        "                    },\n",
        "                    \"radius\": 5000.0\n",
        "                }\n",
        "            },\n",
        "            \"includedTypes\": [\"fire_station\"]\n",
        "        }\n",
        "        headers = {\n",
        "            \"Content-Type\": \"application/json\",\n",
        "            \"X-Goog-Api-Key\": api_key,\n",
        "            \"X-Goog-FieldMask\": \"places.displayName,places.formattedAddress,places.internationalPhoneNumber\"\n",
        "        }\n",
        "        response = requests.post(url, json=payload, headers=headers)\n",
        "        data = response.json()\n",
        "        if response.status_code != 200:\n",
        "            return f\"API Error: {response.status_code}\"\n",
        "        if \"places\" not in data or not data[\"places\"]:\n",
        "            return \"No fire stations found nearby\"\n",
        "        place = data[\"places\"][0]\n",
        "        name = place.get(\"displayName\", {}).get(\"text\", \"Unnamed Fire Station\")\n",
        "        phone = place.get(\"internationalPhoneNumber\", \"Phone number not available\")\n",
        "        address = place.get(\"formattedAddress\", \"Address unavailable\")\n",
        "        return {\n",
        "            \"name\": name,\n",
        "            \"phone\": phone,\n",
        "            \"address\": address\n",
        "        }\n",
        "    except Exception as e:\n",
        "        return f\"Error retrieving phone number: {str(e)}\"\n",
        "\n",
        "# Colab-compatible inference (adapted from first code, Cell 6)\n",
        "def run_inference(model):\n",
        "    print(\"Please upload an image to test!\")\n",
        "    uploaded = files.upload()\n",
        "    file_name = list(uploaded.keys())[0]\n",
        "    print(f\"Got your file: {file_name}\")\n",
        "\n",
        "    classification = classify_image(file_name, model)\n",
        "\n",
        "    if classification == 'Predicted class: Smoke':\n",
        "        location = get_gps_coordinates(file_name)\n",
        "        if location:\n",
        "            lat, lon = location\n",
        "            api_key = \"YOUR_API_KEY\"  # Replace with your Google Places API key\n",
        "            fire_station = get_fire_station_phone_number(lat, lon, api_key)\n",
        "            if isinstance(fire_station, dict):\n",
        "                alert_message = (\n",
        "                    f\"Wildfire detected at:\\n\\n\"\n",
        "                    f\"{lat}, {lon}\\n\\n\"\n",
        "                    f\"Nearest Fire Station:\\n\"\n",
        "                    f\"{fire_station['name']}\\n\"\n",
        "                    f\"{fire_station['phone']}\\n\"\n",
        "                    f\"{fire_station['address']}\"\n",
        "                )\n",
        "            else:\n",
        "                alert_message = (\n",
        "                    f\"Wildfire detected at:\\n\\n\"\n",
        "                    f\"{lat}, {lon}\\n\\n\"\n",
        "                    f\"Nearest Fire Station:\\n\"\n",
        "                    f\"{fire_station}\"\n",
        "                )\n",
        "        else:\n",
        "            alert_message = \"Smoke detected but no location data found.\"\n",
        "    else:\n",
        "        alert_message = classification\n",
        "\n",
        "    print(\"Analysis completed\")\n",
        "    print(alert_message)\n",
        "\n",
        "    os.remove(file_name)\n",
        "    print(f\"Deleted {file_name} from Colab.\")\n",
        "\n",
        "# Main execution (from first code, Cell 5, adapted)\n",
        "if __name__ == \"__main__\":\n",
        "    model = WildfireViTModel()\n",
        "    model_path = \"/content/WEIGHTS/wildfire_model.pth\"  # Weights will be uploaded\n",
        "    if os.path.exists(model_path):\n",
        "        model.load_state_dict(torch.load(model_path, map_location=torch.device('cpu'), weights_only=True))\n",
        "        print(\"Model loaded successfully!\")\n",
        "    else:\n",
        "        print(\"Model weights not found. Please upload wildfire_model.pth to /content/WEIGHTS/ or train the model.\")\n",
        "        # Training (from first code, Cell 5, commented out)\n",
        "        \"\"\"\n",
        "        from torchmetrics import Accuracy, F1Score\n",
        "        def train_and_evaluate(model, train_loader, test_loader, criterion, optimizer, epochs):\n",
        "            device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "            model = model.to(device)\n",
        "            class_count = 6\n",
        "            train_accuracy_metric = Accuracy(task=\"multiclass\", num_classes=class_count).to(device)\n",
        "            val_accuracy_metric = Accuracy(task=\"multiclass\", num_classes=class_count).to(device)\n",
        "            f1_metric = F1Score(task=\"multiclass\", num_classes=class_count, average='macro').to(device)\n",
        "            for epoch in range(epochs):\n",
        "                model.train()\n",
        "                train_loss = 0\n",
        "                train_accuracy_metric.reset()\n",
        "                f1_metric.reset()\n",
        "                for images, labels in train_loader:\n",
        "                    images, labels = images.to(device), labels.to(device)\n",
        "                    optimizer.zero_grad()\n",
        "                    outputs = model(images)\n",
        "                    loss = criterion(outputs, labels)\n",
        "                    loss.backward()\n",
        "                    optimizer.step()\n",
        "                    train_loss += loss.item()\n",
        "                    preds = torch.argmax(outputs, dim=1)\n",
        "                    train_accuracy_metric.update(preds, labels)\n",
        "                    f1_metric.update(preds, labels)\n",
        "                avg_train_loss = train_loss / len(train_loader)\n",
        "                train_accuracy = train_accuracy_metric.compute().item()\n",
        "                train_f1 = f1_metric.compute().item()\n",
        "                model.eval()\n",
        "                val_loss = 0\n",
        "                val_accuracy_metric.reset()\n",
        "                f1_metric.reset()\n",
        "                with torch.no_grad():\n",
        "                    for images, labels in test_loader:\n",
        "                        images, labels = images.to(device), labels.to(device)\n",
        "                        outputs = model(images)\n",
        "                        loss = criterion(outputs, labels)\n",
        "                        val_loss += loss.item()\n",
        "                        preds = torch.argmax(outputs, dim=1)\n",
        "                        val_accuracy_metric.update(preds, labels)\n",
        "                        f1_metric.update(preds, labels)\n",
        "                avg_val_loss = val_loss / len(test_loader)\n",
        "                val_accuracy = val_accuracy_metric.compute().item()\n",
        "                val_f1 = f1_metric.compute().item()\n",
        "                print(f\"Epoch {epoch + 1}:\")\n",
        "                print(f\"  Train Loss: {avg_train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}, Train F1: {train_f1:.4f}\")\n",
        "                print(f\"  Val Loss: {avg_val_loss:.4f}, Val Accuracy: {val_accuracy:.4f}, Val F1: {val_f1:.4f}\")\n",
        "            return model\n",
        "\n",
        "        from google.colab import drive\n",
        "        drive.mount('/content/drive')\n",
        "        image_dir = \"/content/drive/MyDrive/archive\"  # Update with your dataset path\n",
        "        dataset = SatelliteWildfireDataset(image_dir)\n",
        "        train_size = int(0.8 * len(dataset))\n",
        "        test_size = len(dataset) - train_size\n",
        "        train_data, test_data = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
        "        train_loader = DataLoader(train_data, batch_size=16, shuffle=True)\n",
        "        test_loader = DataLoader(test_data, batch_size=16, shuffle=False)\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "        optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "        model = train_and_evaluate(model, train_loader, test_loader, criterion, optimizer, epochs=1)\n",
        "        torch.save(model.state_dict(), \"/content/WEIGHTS/wildfire_model.pth\")\n",
        "        print(\"Model trained and saved!\")\n",
        "        \"\"\"\n",
        "    model.eval()\n",
        "    run_inference(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "id": "pyouGhN3Hfrt",
        "outputId": "93f139f6-f80f-4b32-d635-d47a7bc3dead"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of ViTModel were not initialized from the model checkpoint at google/vit-base-patch16-224 and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model weights not found. Please upload wildfire_model.pth to /content/WEIGHTS/ or train the model.\n",
            "Please upload an image to test!\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-b4a5a1b8-da8a-4612-bab7-6f2a79873dba\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-b4a5a1b8-da8a-4612-bab7-6f2a79873dba\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving smoke_444.tif to smoke_444.tif\n",
            "Got your file: smoke_444.tif\n",
            "Analysis completed\n",
            "No smoke detected\n",
            "Deleted smoke_444.tif from Colab.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "roHWlVhAHfuj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "e1dfDTC4Hfw-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KBvZ-8XRHeq2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}